%!TEX program = xelatex
\documentclass{article}
\usepackage{LaTeX-Submodule/template}

% Additional packages and macros
\usepackage{changepage} % Modify page width
\usepackage{multicol} % Use multiple columns
\usepackage{titlesec} % Modify section heading styles

%% A4 page
\geometry{
	a4paper,
	margin = 10mm
}

% Hide page numbers
\pagenumbering{gobble}

%% Multi-columns setup
\setlength{\columnsep}{4pt}

%% Paragraph setup
\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt}

%% Customise section heading styles
\titleformat*\section{\raggedright\bfseries}

\begin{document}
% Modify spacing
\titlespacing*\section{0pt}{1ex}{1ex}
%
\setlength{\textfloatsep}{0pt}
%
\setlength{\abovedisplayskip}{1pt}
\setlength{\belowdisplayskip}{1pt}
%
\begin{minipage}[t]{62.39259259mm}
    \section*{Vector Spaces}
    A \textbf{vector space} $V$ is closed under vector addition
    and scalar multiplication:
    \begin{equation*}
        \symbfit{u}+\symbfit{v} \in V \ \text{and} \ k\symbfit{u} \in V.
    \end{equation*}
    A \textit{subset} $W$ of a vector space $V$ is called a
    \textbf{subspace} of $V$ if $W$ is itself a vector space. The
    intersection of subspaces is also a subspace of $V$.

    $S$ is \textbf{linearly independent (LI)} if
    \begin{equation*}
        k_1 \symbfit{v}_1 + k_2 \symbfit{v}_2 + \cdots + k_n \symbfit{v}_n = \symbfup{0}
    \end{equation*}
    has $k_i=0$.

    $S$ forms a \textbf{basis} for $V$ if $S$ spans $V$ and
    $S$ is LI.
    \section*{Fundamental Subspaces}
    For $\symbfit{A}\in\mathbb{R}^{m \times n}$:
    \begin{itemize}
        \item $r = \rank{\left( \symbfit{A} \right)} = \dim{\left( \columnspace{A} \right)}$
        \item $r = \rank{\left( \symbfit{A}^\top \right)} = \dim{\left( \rowspace{A} \right)}$
        \item $n - r = \vnull{\left( \symbfit{A} \right)}      = \dim{\left( \nullspace{A} \right)}$
        \item $m - r = \vnull{\left( \symbfit{A}^\top \right)} = \dim{\left( \leftnullspace{A} \right)}$
    \end{itemize}
    \textbf{Row equivalent} matrices have the same
    \underline{row space} and \underline{null space}.
    \section*{Orthogonality}
    The subspaces $U$ and $W$ of a vector space $V$ are
    \textbf{orthogonal subspaces} iff
    \begin{equation*}
        \forall \symbfit{u}\in U:\forall \symbfit{w}\in W:\symbfit{u}^{\top}\symbfit{w} = 0.
    \end{equation*}
    \begin{itemize}
        \item $\symbfit{v}^\top \symbfit{v}=\norm{\symbfit{v}}^2$
    \end{itemize}
    The \textbf{orthogonal complement} of $U$:
    \begin{equation*}
        U^{\perp} = \left\{ \forall \symbfit{u}\in U:\symbfit{v}\in V: \symbfit{v}^{\top}\symbfit{u}=0 \right\}
    \end{equation*}
    \begin{itemize}
        \item $\left( U^{\perp} \right)^{\perp} = U$
        \item $\dim{U} + \dim{U^{\perp}} = \dim{V}$
        \item $\left( \columnspace{A} \right)^\perp = \leftnullspace{A}$
        \item $\left( \rowspace{A} \right)^\perp = \nullspace{A}$
    \end{itemize}
    \textbf{Projections}:
    \begin{equation*}
        \proj_{\symbfit{a}}\symbfit{b}
        = \symbfit{a} x
        = \symbfit{a} \frac{\symbfit{a}^\top \symbfit{b}}{\symbfit{a}^\top \symbfit{a}}.
    \end{equation*}
    \begin{gather*}
        \forall \symbfit{w}\in W:\symbfit{w}\neq \symbfit{p}: \\
        \proj_{W}\symbfit{b} = \symbfit{A}\symbfit{\hat{x}} = \symbfit{A}\left( \symbfit{A}^\top \symbfit{A} \right)^{-1}\symbfit{A}^\top \symbfit{b}: \\
        \norm{\symbfit{b}-\symbfit{p}}<\norm{\symbfit{b}-\symbfit{w}}.
    \end{gather*}
    \section*{Determinants}
    \begin{equation*}
        \det{\left( \symbfit{A} \right)} = \sum_{j=1}^n a_{ij}C_{ij} = \sum_{i=1}^n a_{ij}C_{ij}
    \end{equation*}
    where $C_{ij}=\left( -1 \right)^{i+j}M_{ij}$.
    \begin{equation*}
        \symbfit{A}^{-1}=\frac{1}{\det{\symbfit{A}}} \adj{\left( \symbfit{A} \right)}
    \end{equation*}
    where $\adj{\left( \symbfit{A} \right)}=C^\top$.
\end{minipage}\hfill%
\begin{minipage}[t]{126.1962963mm}
    \section*{Linear Maps}
    \textbf{Linear transformations}:
    \begin{gather*}
        T:V\rightarrow W \iff \forall \symbfit{u},\: \symbfit{v} \in V:\forall k \in \mathbb{R}: \\
        T\left(\symbfit{u}+\symbfit{v}\right) = T\left(\symbfit{u}\right) + T\left(\symbfit{v}\right) \wedge T\left(k\symbfit{u}\right) = kT\left(\symbfit{u}\right)
    \end{gather*}
    \textbf{Rotations}: Anticlockwise looking down from the positive direction of the
    axis of rotation.
    \begin{align*}
        \symbfit{R}_x = \mqty[1                           & 0                            & 0 \\ 0 & \cos{\left( \theta \right)} & -\sin{\left( \theta \right)} \\ 0 & \sin{\left( \theta \right)} & \cos{\left( \theta \right)}] \quad \symbfit{R}_y = \mqty[\cos{\left( \theta \right)} & 0                            & \sin{\left( \theta \right)} \\ 0 & 1 & 0 \\ -\sin{\left( \theta \right)} & 0 & \cos{\left( \theta \right)}] \\
        \symbfit{R}_z = \mqty[\cos{\left( \theta \right)} & -\sin{\left( \theta \right)} & 0 \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)} & 0 \\ 0 & 0 & 1] \quad \symbfit{R} = \mqty[\cos{\left( \theta \right)} & -\sin{\left( \theta \right)} \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)}].
    \end{align*}
    \textbf{Shears}:
    \begin{align*}
        \symbfit{S}_x = \mqty[1 & a & b \\ 0 & 1 & 0 \\ 0 & 0 & 1] \quad
        \symbfit{S}_y=\mqty[1   & 0 & 0 \\ a & 1 & b \\ 0 & 0 & 1] \quad
        \symbfit{S}_z=\mqty[1   & 0 & 0 \\ 0 & 1 & 0 \\ a & b & 1]
    \end{align*}
    where the standard basis vector in the subscripted axis maps to itself.
    Think about where the standard basis vectors maps.

    \textbf{Reflections}:
    \begin{align*}
        \symbfit{M}_{xy}=\mqty[1  & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -1] \quad
        \symbfit{M}_{xz}=\mqty[1  & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 1] \quad
        \symbfit{M}_{yz}=\mqty[-1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1]
    \end{align*}
    where vectors are reflected across the plane formed by the subscripts of
    $\symbfit{M}$.

    \textbf{2d reflections} about $y=mx + c$, where $\theta=\arctan{\left( m \right)}$:
    \begin{align*}
        T\left( \symbfit{v} \right) & = \symbfit{R} \symbfit{M}_{xz} \symbfit{R}^{-1} \left( \symbfit{v} - \mqty[0                                \\ c] \right) + \mqty[0 \\ c] \\
                                    & = \mqty[\cos{\left( \theta \right)}                                          & -\sin{\left( \theta \right)} \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)}] \mqty[1 & 0 \\ 0 & -1] \mqty[\cos{\left( \theta \right)} & -\sin{\left( \theta \right)} \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)}]^{-1} \left( \symbfit{v} - \mqty[0 \\ c] \right) + \mqty[0 \\ c] \\
                                    & = \frac{1}{1+m^2}\mqty[1-m^2                                                 & 2m                           \\ 2m & m^2-1] \left( \symbfit{v} - \mqty[0 \\ c] \right) + \mqty[0 \\ c] \\
    \end{align*}
    \begin{multicols*}{2}
        \section*{Invariant Subspaces}
        \textbf{Invariant (IV) subspaces}:

        For $T:V\rightarrow V$, $\mathcal{V}$ is IV if
        \begin{equation*}
            T\left(\mathcal{V}\right)\subseteq \mathcal{V}\iff\forall \symbfit{v}
            \in \mathcal{V}\implies T\left(\symbfit{v}\right)\in \mathcal{V}.
        \end{equation*}
        \textbf{Trivial IV subspaces}:
        \begin{enumerate}
            \item $V$
            \item $\vim{\left( T \right)} \equiv T(V) = \left\{ T\left(\symbfit{v}\right) : \symbfit{v}\in V \right\}$
            \item $\vker{\left( T \right)} = \left\{ \symbfit{v}\in V : T\left(\symbfit{v}\right) = \symbfup{0} \right\}$
            \item $\left\{ \symbfup{0} \right\}$
            \item linear combination of IV subspaces
        \end{enumerate}
        \textbf{Eigenspaces} (1d IV subspace):
        \begin{equation*}
            \mathcal{V} = \left\{ \forall \symbfit{q}\in \mathcal{V}:\exists
            \lambda \in \mathbb{C}:T\left(\symbfit{q}\right) = \lambda \symbfit{q} \right\}
        \end{equation*}
        where $\lambda_i$ are the eigenvalues of $\symbfit{A}$ and
        $\symbfit{q}_i$ are the eigenvectors of $\symbfit{A}$, and they satisfy
        $\left( \symbfit{A} - \lambda \mathbb{1} \right) \symbfit{q}=\symbfup{0}$.

        If $\symbfit{A}$ is invertible:
        $\det{\left( \symbfit{A} - \lambda\mathbb{1} \right)} = 0$.

        \textbf{Characteristic polynomial}:
        \begin{equation*}
            p_n\left(\lambda\right) = \det{\left( \symbfit{A}_n - \lambda\mathbb{1}_n \right)}
        \end{equation*}
        \textbf{In 2d}:
        \begin{equation*}
            p_2\left(\lambda\right) = \lambda^2-\tr{\left( \symbfit{A} \right)}\lambda + \det{\left( \symbfit{A} \right)}
        \end{equation*}
        \begin{equation*}
            \tr{\left( \symbfit{A} \right)} = \sum_{i=1}^n \lambda_i \quad \text{and} \quad
            \det{\left( \symbfit{A} \right)} = \prod_{i=1}^n \lambda_i
        \end{equation*}
        \textbf{Similarity transformation}:
        \begin{equation*}
            \symbfit{A}\rightarrow \symbfit{Q}^{-1}\symbfit{A}\symbfit{Q}
        \end{equation*}
        If $\symbfit{q}_i$ are LI, then $\symbfit{A}$ is
        \textbf{diagonalisable}:
        \begin{equation*}
            \symbfit{\Lambda}=\symbfit{Q}^{-1}\symbfit{A}\symbfit{Q} \iff \symbfit{A}=\symbfit{Q}\symbfit{\Lambda}\symbfit{Q}^{-1}
        \end{equation*}
    \end{multicols*}
    If $\symbfit{A}$ is diagonalisable:
    \begin{equation*}
        \symbfit{\Lambda}=\mqty[\dmat{\lambda_1,\: \lambda_2,\: \ddots,\: \lambda_n}] \quad
        \symbfit{Q}=\mqty[\vertbar & \vertbar & & \vertbar \\ \symbfit{q}_1 &
            \symbfit{q}_2 & \cdots & \symbfit{q}_n \\ \vertbar & \vertbar & & \vertbar]
    \end{equation*}
    \begin{equation*}
        \forall k \in \mathbb{N}_0:\symbfit{A}^k = \symbfit{Q} \symbfit{\Lambda}^k \symbfit{Q}^{-1}
    \end{equation*}
    The eigenvalues of $\symbfit{A}^k$ are the eigenvalues of $\symbfit{A}$
    to the $k$-th power: $\lambda_1^k,\: \lambda_2^k,\: \dots,\: \lambda_n^k$.

    The eigenvectors of $\symbfit{A}^k$ equal the eigenvectors of $\symbfit{A}$.
\end{minipage}
\begin{multicols*}{2}

    \section*{Differential Equations}
    The \textbf{ordinary differential equation (ODE)}: $x' = a x$,
    has the solution: $x(t) = c_1 \e^{a t}$. $c_1$ is determined through
    initial conditions.

    The \textbf{system of differential equations}:
    \begin{align*}
               & \left\{
        \setlength\arraycolsep{0pt}
        \begin{array}{ c >{{}}c<{{}} c >{{}}c<{{}} c >{{}}c<{{}} c >{{}}c<{{}} c  }
            x'_1               & = & a_{11}x_1                         & + & a_{12}x_2                         & + & \cdots & + & a_{1n}x_n                         \\
            x'_2               & = & a_{21}x_1                         & + & a_{22}x_2                         & + & \cdots & + & a_{2n}x_n                         \\
            \vdotswithin{x'_3} &   & \vdotswithin{a_{31}}\phantom{x_1} &   & \vdotswithin{a_{32}}\phantom{x_2} &   &        &   & \vdotswithin{a_{3n}}\phantom{x_n} \\
            x'_n               & = & a_{n1}x_1                         & + & a_{n2}x_2                         & + & \cdots & + & a_{nn}x_n
        \end{array}
        \right.                                                           \\
        \iff
               & \dv{t}\mqty[x_1                                          \\ x_2 \\ \vdots \\ x_n] = \mqty[
        a_{11} & a_{12}                                 & \cdots & a_{1n} \\
        a_{21} & a_{22}                                 & \cdots & a_{2n} \\
        \vdots & \vdots                                 &        & \vdots \\
        a_{n1} & a_{n2}                                 & \cdots & a_{nn}
        ] \mqty[x_1                                                       \\ x_2 \\ \vdots \\ x_n] \\
        \iff   & \symbfit{x}' = \symbfit{A} \symbfit{x}
    \end{align*}
    can be solved using $\symbfit{x}=\symbfit{Q}\symbfit{u}$ where
    $\symbfit{Q}$ is the matrix that diagonalises $\symbfit{A}$ and
    $\symbfit{u}$ is the solution to $\symbfit{u}' = \symbfit{\Lambda} \symbfit{u}$ where
    $\symbfit{\Lambda}$ is the diagonal similarity transformation of $\symbfit{A}$.

    If $\symbfit{A}$ is diagonalisable, then for $\symbfit{x}' = \symbfit{A} \symbfit{x}$:
    \begin{equation*}
        \symbfit{x}(t) = c_1 \e^{\lambda_1 t} \symbfit{q}_1 + c_2 \e^{\lambda_2 t} \symbfit{q}_2 + \cdots + c_n \e^{\lambda_n t} \symbfit{q}_n
    \end{equation*}
    For the \textbf{higher-order linear differential equation}:
    \begin{equation*}
        x^{\left( n \right)} + a_1 x^{\left( n-1 \right)} + \cdots + a_{n-1} x' + a_n x = 0
    \end{equation*}
    define
    \begin{equation*}
        x_1 = x,\: x_2 = x',\: \dots,\: x_n = x^{\left( n-1 \right)}
    \end{equation*}
    and let
    \begin{equation*}
        \symbfit{x}=\mqty[x_1 \\ x_2 \\ \cdots \\ x_n].
    \end{equation*}
    Then solve the following ODE using diagonalisation:
    \begin{equation*}
        \dv{t}\mqty[
            x_1 \\
            x_2 \\
            \vdotswithin{x_3} \\
            x_n
        ] = \mqty[
        0 & 1 & 0 & \cdots & 0 \\
        0 & 0 & 1 & \cdots & 0 \\
        \vdots & \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & 0 & \cdots & 1 \\
        -a_n & -a_{n-1} & -a_{n-2} & \cdots & -a_1
        ] \mqty[
            x_1 \\
            x_2 \\
            \vdotswithin{x_3} \\
            x_n
        ].
    \end{equation*}
    \section*{Vector Operations}
    \textbf{Norm of a vector}:
    \begin{equation*}
        \norm{\symbfit{v}} = \sqrt{v_1^2 + v_2^2+\dots+v_n^2}
    \end{equation*}
    \textbf{Unit vector}:
    \begin{equation*}
        \symbfit{\hat{v}} = \frac{\symbfit{v}}{\norm{\symbfit{v}}}
    \end{equation*}
    \textbf{Dot product}:
    \begin{align*}
        \symbfit{v}\cdot\symbfit{w} & = v_1 w_1 + v_2 w_2 + \cdots + v_n w_n                            \\
                                    & = \norm{\symbfit{v}} \norm{\symbfit{w}} \cos{\left(\theta\right)}
    \end{align*}
    \textbf{Cross product}:
    \begin{align*}
        \symbfit{v}\times\symbfit{w} & =
        \mqty|
        \symbfit{\hat{i}}            & \symbfit{\hat{j}} & \symbfit{\hat{k}} \\
        v_1                          & v_2               & v_3               \\
        w_1                          & w_2               & w_3
        |                                                                    \\
                                     & =
        \norm{\symbfit{v}}\norm{\symbfit{w}}\sin{\left(\theta\right)}\symbfit{\hat{n}}
    \end{align*}
    \textbf{2-d Inverse}:
    \begin{equation*}
        \mqty[a & b \\ c & d]^{-1} = \frac{1}{ad - bc} \mqty[d & -b \\ -c & a]
    \end{equation*}
    \section*{Vector Space Axioms}
    \textbf{Closure under addition}:
    \begin{equation*}
        \symbfit{u}+\symbfit{v} \in V
    \end{equation*}
    \textbf{Commutativity of vector addition}:
    \begin{equation*}
        \symbfit{u} + \symbfit{v} = \symbfit{v} + \symbfit{u}
    \end{equation*}
    \textbf{Associativity of vector addition}:
    \begin{equation*}
        \symbfit{u} + \left(\symbfit{v} + \symbfit{w}\right) =
        \left(\symbfit{u} + \symbfit{v}\right) + \symbfit{w}
    \end{equation*}
    \textbf{Additive identity}:
    \begin{equation*}
        \symbfit{u} + \symbfup{0} = \symbfit{u}
    \end{equation*}
    \textbf{Additive inverse}:
    \begin{equation*}
        \symbfit{u} + \left(-\symbfit{u}\right) = \symbfup{0}
    \end{equation*}
    \textbf{Closure under scalar multiplication}:
    \begin{equation*}
        k\symbfit{u} \in V
    \end{equation*}
    \textbf{Distributivity of vector addition}:
    \begin{equation*}
        k \left(\symbfit{u} + \symbfit{v}\right) = k\symbfit{u} + k\symbfit{v}
    \end{equation*}
    \textbf{Distributivity of scalar addition}:
    \begin{equation*}
        \left(k+m\right)\symbfit{u} = k\symbfit{u} + m\symbfit{u}
    \end{equation*}
    \textbf{Associativity of scalar multiplication}:
    \begin{equation*}
        k\left(m\symbfit{u}\right)=\left(km\right)\symbfit{u}
    \end{equation*}
    \textbf{Scalar multiplication identity}:
    \begin{equation*}
        1 \symbfit{u}=\symbfit{u}
    \end{equation*}
    \section*{Subspaces}
    \textbf{Subspaces of $\mathbb{R}^2$}: $\left\{ \symbfup{0} \right\}$,
    lines through the origin, and $\mathbb{R}^2$.

    \textbf{Subspaces of $\mathbb{R}^3$}: $\left\{ \symbfup{0} \right\}$,
    lines through the origin, planes through the origin, and $\mathbb{R}^3$.

    \textbf{Subspaces of $\symbfit{M}_{nn}$}: Upper triangular matrices,
    lower triangular matrices, diagonal matrices, and $\symbfit{M}_{nn}$.
    \section*{Determinant Properties}
    \begin{enumerate}
        \item $\det{\left( \mathbb{1} \right)}=1$
        \item Exchanging two rows of a matrix reverses the sign of its determinant
        \item Determinants are multilinear, so that
              \begin{equation*}
                  \mdet{a+a' & b+b' \\ c & d}
                  = \mdet{a & b \\ c & d}+\mdet{a' & b' \\ c & d}
              \end{equation*}
              and
              \begin{equation*}
                  \mdet{ta & tb \\ c & d}=t\mdet{a & b \\ c & d}
              \end{equation*}
        \item If $\symbfit{A}$ has two equal rows, then $\det{\left( \symbfit{A} \right)}=0$
        \item Adding a scalar multiple of one row to another does not change the determinant of a matrix
        \item If $\symbfit{A}$ has a row of zeros, then $\det{\left( \symbfit{A} \right)}=0$
        \item If $\symbfit{A}$ is triangular, then $\det{\left( \symbfit{A} \right)}=\prod_{i=1}^{n} a_{ii}$
        \item If $\symbfit{A}$ is singular, then $\det{\left( \symbfit{A} \right)}=0$
        \item $\det{\left( \symbfit{A}\symbfit{B} \right)} = \det{\left( \symbfit{A} \right)}\det{\left( \symbfit{B} \right)}$
        \item $\det{\left( \symbfit{A}^\top \right)} = \det{\left( \symbfit{A} \right)}$
    \end{enumerate}
    \section*{Matrix Identities}
    \begin{enumerate}
        \item $\symbfit{A}\left( \symbfit{B}\symbfit{C} \right) = \symbfit{A}\symbfit{B}+\symbfit{A}\symbfit{C}$
        \item $\left( \symbfit{A}+\symbfit{B} \right)^\top = \symbfit{A}^\top + \symbfit{B}^\top$
        \item $\left( \symbfit{A}\symbfit{B} \right)^\top = \symbfit{B}^\top \symbfit{A}^\top$
        \item If $\symbfit{A}$ and $\symbfit{B}$ are both invertible:
              \begin{enumerate}
                  \item $\left( \symbfit{A}\symbfit{B} \right)^{-1} = \symbfit{B}^{-1}\symbfit{A}^{-1}$
                  \item $\left( \symbfit{A}^{-1} \right)^\top = \left( \symbfit{A}^\top \right)^{-1}$
              \end{enumerate}
    \end{enumerate}
\end{multicols*}
\end{document}