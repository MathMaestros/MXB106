%!TEX program = xelatex
\documentclass{article}
\usepackage{LaTeX-Submodule/template}

% Additional packages and macros
\usepackage{changepage} % Modify page width
\usepackage{multicol} % Use multiple columns
\usepackage{titlesec} % Modify section heading styles

%% A4 page
\geometry{
	a4paper,
	margin = 10mm
}

%% Hide horizontal rule 
\renewcommand{\headrulewidth}{0pt}

% Hide page numbers
\pagenumbering{gobble}

%% Multi-columns setup
\setlength{\columnsep}{4pt}

%% Paragraph setup
\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt}

%% Customise section heading styles
\titleformat*\section{\raggedright\bfseries}

\begin{document}
% Modify spacing
\titlespacing*\section{0pt}{1ex}{1ex}
%
\setlength{\textfloatsep}{0pt}
%
\setlength{\abovedisplayskip}{1pt}
\setlength{\belowdisplayskip}{1pt}
%
\begin{minipage}[t]{62.39259259mm}
    \section*{Vector Spaces}
    A \textbf{vector space} \(V\) is closed under vector addition
    and scalar multiplication:
    \begin{equation*}
        \symbfit{u}+\symbfit{v} \in V \ \text{and} \ k\symbfit{u} \in V.
    \end{equation*}
    A \textit{subset} \(W\) of a vector space \(V\) is called a
    \textbf{subspace} of \(V\) if \(W\) is itself a vector space. The
    intersection of subspaces is also a subspace of \(V\).

    \(S\) is \textbf{linearly independent (LI)} if
    \begin{equation*}
        k_1 \symbfit{v}_1 + k_2 \symbfit{v}_2 + \cdots + k_n \symbfit{v}_n = \symbfup{0}
    \end{equation*}
    has \(k_i=0\).

    \(S\) forms a \textbf{basis} for \(V\) if \(S\) spans \(V\) and
    \(S\) is LI.
    \section*{Fundamental Subspaces}
    For \(\symbf{A}\in\mathbb{R}^{m \times n}\):
    \begin{itemize}
        \item \(r = \rank{\left( \symbf{A} \right)} = \dim{\left( \columnspace{A} \right)}\)
        \item \(r = \rank{\left( \symbf{A}^\top \right)} = \dim{\left( \rowspace{A} \right)}\)
        \item \(n - r = \vnull{\left( \symbf{A} \right)}      = \dim{\left( \nullspace{A} \right)}\)
        \item \(m - r = \vnull{\left( \symbf{A}^\top \right)} = \dim{\left( \leftnullspace{A} \right)}\)
    \end{itemize}
    \textbf{Row equivalent} matrices have the same
    \underline{row space} and \underline{null space}.
    \section*{Orthogonality}
    The subspaces \(U\) and \(W\) of a vector space \(V\) are
    \textbf{orthogonal subspaces} iff
    \begin{equation*}
        \forall \symbfit{u}\in U:\forall \symbfit{w}\in W:\symbfit{u}^{\top}\symbfit{w} = 0.
    \end{equation*}
    \begin{itemize}
        \item \(\symbfit{v}^\top \symbfit{v}=\norm{\symbfit{v}}^2\)
    \end{itemize}
    The \textbf{orthogonal complement} of \(U\):
    \begin{equation*}
        U^{\perp} = \left\{ \forall \symbfit{u}\in U:\symbfit{v}\in V: \symbfit{v}^{\top}\symbfit{u}=0 \right\}
    \end{equation*}
    \begin{itemize}
        \item \(\left( U^{\perp} \right)^{\perp} = U\)
        \item \(\dim{U} + \dim{U^{\perp}} = \dim{V}\)
        \item \(\left( \columnspace{A} \right)^\perp = \leftnullspace{A}\)
        \item \(\left( \rowspace{A} \right)^\perp = \nullspace{A}\)
    \end{itemize}
    \textbf{Projections}:
    \begin{equation*}
        \proj_{\symbfit{a}}\symbfit{b}
        = \symbfit{a} x
        = \symbfit{a} \frac{\symbfit{a}^\top \symbfit{b}}{\symbfit{a}^\top \symbfit{a}}.
    \end{equation*}
    \begin{gather*}
        \forall \symbfit{w}\in W:\symbfit{w}\neq \symbfit{p}: \\
        \proj_{W}\symbfit{b} = \symbf{A}\symbfit{\hat{x}} = \symbf{A}\left( \symbf{A}^\top \symbf{A} \right)^{-1}\symbf{A}^\top \symbfit{b}: \\
        \norm{\symbfit{b}-\symbfit{p}}<\norm{\symbfit{b}-\symbfit{w}}.
    \end{gather*}
    \section*{Determinants}
    \begin{equation*}
        \det{\left( \symbf{A} \right)} = \sum_{j=1}^n a_{ij}C_{ij} = \sum_{i=1}^n a_{ij}C_{ij}
    \end{equation*}
    where \(C_{ij}=\left( -1 \right)^{i+j}M_{ij}\).
    \begin{equation*}
        \symbf{A}^{-1}=\frac{1}{\det{\symbf{A}}} \adj{\left( \symbf{A} \right)}
    \end{equation*}
    where \(\adj{\left( \symbf{A} \right)}=C^\top\).
\end{minipage}\hfill%
\begin{minipage}[t]{126.1962963mm}
    \section*{Linear Maps}
    \textbf{Linear transformations}:
    \begin{gather*}
        T:V\rightarrow W \iff \forall \symbfit{u},\: \symbfit{v} \in V:\forall k \in \mathbb{R}: \\
        T\left(\symbfit{u}+\symbfit{v}\right) = T\left(\symbfit{u}\right) + T\left(\symbfit{v}\right) \wedge T\left(k\symbfit{u}\right) = kT\left(\symbfit{u}\right)
    \end{gather*}
    \textbf{Rotations}: Anticlockwise looking down from the positive direction of the
    axis of rotation.
    \begin{align*}
        \symbfit{R}_x = \mqty[1                           & 0                            & 0 \\ 0 & \cos{\left( \theta \right)} & -\sin{\left( \theta \right)} \\ 0 & \sin{\left( \theta \right)} & \cos{\left( \theta \right)}] \quad \symbfit{R}_y = \mqty[\cos{\left( \theta \right)} & 0                            & \sin{\left( \theta \right)} \\ 0 & 1 & 0 \\ -\sin{\left( \theta \right)} & 0 & \cos{\left( \theta \right)}] \\
        \symbfit{R}_z = \mqty[\cos{\left( \theta \right)} & -\sin{\left( \theta \right)} & 0 \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)} & 0 \\ 0 & 0 & 1] \quad \symbfit{R} = \mqty[\cos{\left( \theta \right)} & -\sin{\left( \theta \right)} \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)}].
    \end{align*}
    \textbf{Shears}:
    \begin{align*}
        \symbfit{S}_x = \mqty[1 & a & b \\ 0 & 1 & 0 \\ 0 & 0 & 1] \quad
        \symbfit{S}_y=\mqty[1   & 0 & 0 \\ a & 1 & b \\ 0 & 0 & 1] \quad
        \symbfit{S}_z=\mqty[1   & 0 & 0 \\ 0 & 1 & 0 \\ a & b & 1]
    \end{align*}
    where the standard basis vector in the subscripted axis maps to itself.
    Think about where the standard basis vectors maps.

    \textbf{Reflections}:
    \begin{align*}
        \symbfit{M}_{xy}=\mqty[1  & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -1] \quad
        \symbfit{M}_{xz}=\mqty[1  & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 1] \quad
        \symbfit{M}_{yz}=\mqty[-1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1]
    \end{align*}
    where vectors are reflected across the plane formed by the subscripts of
    \(\symbfit{M}\).

    \textbf{2d reflections} about \(y=mx + c\), where \(\theta=\arctan{\left( m \right)}\):
    \begin{align*}
        T\left( \symbfit{v} \right) & = \symbfit{R} \symbfit{M}_{xz} \symbfit{R}^{-1} \left( \symbfit{v} - \mqty[0                                \\ c] \right) + \mqty[0 \\ c] \\
                                    & = \mqty[\cos{\left( \theta \right)}                                          & -\sin{\left( \theta \right)} \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)}] \mqty[1 & 0 \\ 0 & -1] \mqty[\cos{\left( \theta \right)} & -\sin{\left( \theta \right)} \\ \sin{\left( \theta \right)} & \cos{\left( \theta \right)}]^{-1} \left( \symbfit{v} - \mqty[0 \\ c] \right) + \mqty[0 \\ c] \\
                                    & = \frac{1}{1+m^2}\mqty[1-m^2                                                 & 2m                           \\ 2m & m^2-1] \left( \symbfit{v} - \mqty[0 \\ c] \right) + \mqty[0 \\ c] \\
    \end{align*}
    \begin{multicols*}{2}
        \section*{Invariant Subspaces}
        \textbf{Invariant (IV) subspaces}:

        For \(T:V\rightarrow V\), \(\mathcal{V}\) is IV if
        \begin{equation*}
            T\left(\mathcal{V}\right)\subseteq \mathcal{V}\iff\forall \symbfit{v}
            \in \mathcal{V}\implies T\left(\symbfit{v}\right)\in \mathcal{V}.
        \end{equation*}
        \textbf{Trivial IV subspaces}:
        \begin{enumerate}
            \item \(V\)
            \item \(\vim{\left( T \right)} \equiv T(V) = \left\{ T\left(\symbfit{v}\right) : \symbfit{v}\in V \right\}\)
            \item \(\vker{\left( T \right)} = \left\{ \symbfit{v}\in V : T\left(\symbfit{v}\right) = \symbfup{0} \right\}\)
            \item \(\left\{ \symbfup{0} \right\}\)
            \item linear combination of IV subspaces
        \end{enumerate}
        \textbf{Eigenspaces} (1d IV subspace):
        \begin{equation*}
            \mathcal{V} = \left\{ \forall \symbfit{q}\in \mathcal{V}:\exists
            \lambda \in \mathbb{C}:T\left(\symbfit{q}\right) = \lambda \symbfit{q} \right\}
        \end{equation*}
        where \(\lambda_i\) are the eigenvalues of \(\symbf{A}\) and
        \(\symbfit{q}_i\) are the eigenvectors of \(\symbf{A}\), and they satisfy
        \(\left( \symbf{A} - \lambda \symbf{I} \right) \symbfit{q}=\symbfup{0}\).

        If \(\symbf{A}\) is invertible:
        \(\det{\left( \symbf{A} - \lambda\symbf{I} \right)} = 0\).

        \textbf{Characteristic polynomial}:
        \begin{equation*}
            p_n\left(\lambda\right) = \det{\left( \symbf{A}_n - \lambda\symbf{I}_n \right)}
        \end{equation*}
        \textbf{In 2d}:
        \begin{equation*}
            p_2\left(\lambda\right) = \lambda^2-\tr{\left( \symbf{A} \right)}\lambda + \det{\left( \symbf{A} \right)}
        \end{equation*}
        \begin{equation*}
            \tr{\left( \symbf{A} \right)} = \sum_{i=1}^n \lambda_i \quad \text{and} \quad
            \det{\left( \symbf{A} \right)} = \prod_{i=1}^n \lambda_i
        \end{equation*}
        \textbf{Similarity transformation}:
        \begin{equation*}
            \symbf{A}\rightarrow \symbf{Q}^{-1}\symbf{A}\symbf{Q}
        \end{equation*}
        If \(\symbfit{q}_i\) are LI, then \(\symbf{A}\) is
        \textbf{diagonalisable}:
        \begin{equation*}
            \symbf{\Lambda}=\symbf{Q}^{-1}\symbf{A}\symbf{Q} \iff \symbf{A}=\symbf{Q}\symbf{\Lambda}\symbf{Q}^{-1}
        \end{equation*}
    \end{multicols*}
    If \(\symbf{A}\) is diagonalisable:
    \begin{equation*}
        \symbf{\Lambda}=\mqty[\dmat{\lambda_1,\: \lambda_2,\: \odifots,\: \lambda_n}] \quad
        \symbf{Q}=\mqty[\vertbar & \vertbar & & \vertbar \\ \symbfit{q}_1 &
            \symbfit{q}_2 & \cdots & \symbfit{q}_n \\ \vertbar & \vertbar & & \vertbar]
    \end{equation*}
    \begin{equation*}
        \forall k \in \mathbb{N}_0:\symbf{A}^k = \symbf{Q} \symbf{\Lambda}^k \symbf{Q}^{-1}
    \end{equation*}
    The eigenvalues of \(\symbf{A}^k\) are the eigenvalues of \(\symbf{A}\)
    to the \(k\)-th power: \(\lambda_1^k,\: \lambda_2^k,\: \dots,\: \lambda_n^k\).

    The eigenvectors of \(\symbf{A}^k\) equal the eigenvectors of \(\symbf{A}\).
\end{minipage}
\section*{Differential Equations}
The \textbf{ordinary differential equation (ODE)}: \(x' = a x\),
has the solution: \(x(t) = c_1 e^{a t}\). \(c_1\) is determined through
initial conditions.
\begin{multicols*}{2}
    The \textbf{system of differential equations}:
    \begin{align*}
               & \left\{
        \setlength\arraycolsep{0pt}
        \begin{array}{ c >{{}}c<{{}} c >{{}}c<{{}} c >{{}}c<{{}} c >{{}}c<{{}} c  }
            x'_1               & = & a_{11}x_1                         & + & a_{12}x_2                         & + & \cdots & + & a_{1n}x_n                         \\
            x'_2               & = & a_{21}x_1                         & + & a_{22}x_2                         & + & \cdots & + & a_{2n}x_n                         \\
            \vdotswithin{x'_3} &   & \vdotswithin{a_{31}}\phantom{x_1} &   & \vdotswithin{a_{32}}\phantom{x_2} &   &        &   & \vdotswithin{a_{3n}}\phantom{x_n} \\
            x'_n               & = & a_{n1}x_1                         & + & a_{n2}x_2                         & + & \cdots & + & a_{nn}x_n
        \end{array}
        \right.                                                           \\
        \iff
               & \odv{t}\mqty[x_1                                          \\ x_2 \\ \vdots \\ x_n] = \mqty[
        a_{11} & a_{12}                                 & \cdots & a_{1n} \\
        a_{21} & a_{22}                                 & \cdots & a_{2n} \\
        \vdots & \vdots                                 &        & \vdots \\
        a_{n1} & a_{n2}                                 & \cdots & a_{nn}
        ] \mqty[x_1                                                       \\ x_2 \\ \vdots \\ x_n] \\
        \iff   & \symbfit{x}' = \symbf{A} \symbfit{x}
    \end{align*}
    can be solved using \(\symbfit{x}=\symbf{Q}\symbfit{u}\) where
    \(\symbf{Q}\) is the matrix that diagonalises \(\symbf{A}\) and
    \(\symbfit{u}\) is the solution to \(\symbfit{u}' = \symbf{\Lambda} \symbfit{u}\) where
    \(\symbf{\Lambda}\) is the diagonal similarity transformation of \(\symbf{A}\).

    If \(\symbf{A}\) is diagonalisable, then for \(\symbfit{x}' = \symbf{A} \symbfit{x}\):
    \begin{equation*}
        \symbfit{x}(t) = c_1 e^{\lambda_1 t} \symbfit{q}_1 + c_2 e^{\lambda_2 t} \symbfit{q}_2 + \cdots + c_n e^{\lambda_n t} \symbfit{q}_n
    \end{equation*}
    For the \textbf{higher-order linear differential equation}:
    \begin{equation*}
        x^{\left( n \right)} + a_1 x^{\left( n-1 \right)} + \cdots + a_{n-1} x' + a_n x = 0
    \end{equation*}
    define
    \begin{equation*}
        x_1 = x,\: x_2 = x',\: \dots,\: x_n = x^{\left( n-1 \right)}
    \end{equation*}
    and let
    \begin{equation*}
        \symbfit{x}=\mqty[x_1 \\ x_2 \\ \cdots \\ x_n].
    \end{equation*}
    Then solve the following ODE using diagonalisation:
    \begin{equation*}
        \odv{t}\mqty[
            x_1 \\
            x_2 \\
            \vdotswithin{x_3} \\
            x_n
        ] = \mqty[
        0 & 1 & 0 & \cdots & 0 \\
        0 & 0 & 1 & \cdots & 0 \\
        \vdots & \vdots & \vdots & \odifots & \vdots \\
        0 & 0 & 0 & \cdots & 1 \\
        -a_n & -a_{n-1} & -a_{n-2} & \cdots & -a_1
        ] \mqty[
            x_1 \\
            x_2 \\
            \vdotswithin{x_3} \\
            x_n
        ].
    \end{equation*}
    \section*{Vector Operations}
    \textbf{Norm of a vector}:
    \begin{equation*}
        \norm{\symbfit{v}} = \sqrt{v_1^2 + v_2^2+\dots+v_n^2}
    \end{equation*}
    \textbf{Unit vector}:
    \begin{equation*}
        \symbfit{\hat{v}} = \frac{\symbfit{v}}{\norm{\symbfit{v}}}
    \end{equation*}
    \textbf{Dot product}:
    \begin{align*}
        \symbfit{v}\cdot\symbfit{w} & = v_1 w_1 + v_2 w_2 + \cdots + v_n w_n                            \\
                                    & = \norm{\symbfit{v}} \norm{\symbfit{w}} \cos{\left(\theta\right)}
    \end{align*}
    \textbf{Cross product}:
    \begin{align*}
        \symbfit{v}\times\symbfit{w} & =
        \mqty|
        \symbfit{\hat{i}}            & \symbfit{\hat{j}} & \symbfit{\hat{k}} \\
        v_1                          & v_2               & v_3               \\
        w_1                          & w_2               & w_3
        |                                                                    \\
                                     & =
        \norm{\symbfit{v}}\norm{\symbfit{w}}\sin{\left(\theta\right)}\symbfit{\hat{n}}
    \end{align*}
    \textbf{2-d Inverse}:
    \begin{equation*}
        \mqty[a & b \\ c & d]^{-1} = \frac{1}{ad - bc} \mqty[d & -b \\ -c & a]
    \end{equation*}
    \section*{Vector Space Axioms}
    \textbf{Closure under addition}:
    \begin{equation*}
        \symbfit{u}+\symbfit{v} \in V
    \end{equation*}
    \textbf{Commutativity of vector addition}:
    \begin{equation*}
        \symbfit{u} + \symbfit{v} = \symbfit{v} + \symbfit{u}
    \end{equation*}
    \textbf{Associativity of vector addition}:
    \begin{equation*}
        \symbfit{u} + \left(\symbfit{v} + \symbfit{w}\right) =
        \left(\symbfit{u} + \symbfit{v}\right) + \symbfit{w}
    \end{equation*}
    \textbf{Additive identity}:
    \begin{equation*}
        \symbfit{u} + \symbfup{0} = \symbfit{u}
    \end{equation*}
    \textbf{Additive inverse}:
    \begin{equation*}
        \symbfit{u} + \left(-\symbfit{u}\right) = \symbfup{0}
    \end{equation*}
    \textbf{Closure under scalar multiplication}:
    \begin{equation*}
        k\symbfit{u} \in V
    \end{equation*}
    \textbf{Distributivity of vector addition}:
    \begin{equation*}
        k \left(\symbfit{u} + \symbfit{v}\right) = k\symbfit{u} + k\symbfit{v}
    \end{equation*}
    \textbf{Distributivity of scalar addition}:
    \begin{equation*}
        \left(k+m\right)\symbfit{u} = k\symbfit{u} + m\symbfit{u}
    \end{equation*}
    \textbf{Associativity of scalar multiplication}:
    \begin{equation*}
        k\left(m\symbfit{u}\right)=\left(km\right)\symbfit{u}
    \end{equation*}
    \textbf{Scalar multiplication identity}:
    \begin{equation*}
        1 \symbfit{u}=\symbfit{u}
    \end{equation*}
    \section*{Subspaces}
    \textbf{Subspaces of \(\mathbb{R}^2\)}: \(\left\{ \symbfup{0} \right\}\),
    lines through the origin, and \(\mathbb{R}^2\).

    \textbf{Subspaces of \(\mathbb{R}^3\)}: \(\left\{ \symbfup{0} \right\}\),
    lines through the origin, planes through the origin, and \(\mathbb{R}^3\).

    \textbf{Subspaces of \(\symbfit{M}_{nn}\)}: Upper triangular matrices,
    lower triangular matrices, diagonal matrices, and \(\symbfit{M}_{nn}\).
    \section*{Determinant Properties}
    \begin{enumerate}
        \item \(\det{\left( \symbf{I} \right)}=1\)
        \item Exchanging two rows of a matrix reverses the sign of its determinant
        \item Determinants are multilinear, so that
              \begin{equation*}
                  \mdet{a+a' & b+b' \\ c & d}
                  = \mdet{a & b \\ c & d}+\mdet{a' & b' \\ c & d}
              \end{equation*}
              and
              \begin{equation*}
                  \mdet{ta & tb \\ c & d}=t\mdet{a & b \\ c & d}
              \end{equation*}
        \item If \(\symbf{A}\) has two equal rows, then \(\det{\left( \symbf{A} \right)}=0\)
        \item Adding a scalar multiple of one row to another does not change the determinant of a matrix
        \item If \(\symbf{A}\) has a row of zeros, then \(\det{\left( \symbf{A} \right)}=0\)
        \item If \(\symbf{A}\) is triangular, then \(\det{\left( \symbf{A} \right)}=\prod_{i=1}^{n} a_{ii}\)
        \item If \(\symbf{A}\) is singular, then \(\det{\left( \symbf{A} \right)}=0\)
        \item \(\det{\left( \symbf{A}\symbfit{B} \right)} = \det{\left( \symbf{A} \right)}\det{\left( \symbfit{B} \right)}\)
        \item \(\det{\left( \symbf{A}^\top \right)} = \det{\left( \symbf{A} \right)}\)
    \end{enumerate}
    \section*{Matrix Identities}
    \begin{enumerate}
        \item \(\symbf{A}\left( \symbfit{B}\symbfit{C} \right) = \symbf{A}\symbfit{B}+\symbf{A}\symbfit{C}\)
        \item \(\left( \symbf{A}+\symbfit{B} \right)^\top = \symbf{A}^\top + \symbfit{B}^\top\)
        \item \(\left( \symbf{A}\symbfit{B} \right)^\top = \symbfit{B}^\top \symbf{A}^\top\)
        \item If \(\symbf{A}\) and \(\symbfit{B}\) are both invertible:
              \begin{enumerate}
                  \item \(\left( \symbf{A}\symbfit{B} \right)^{-1} = \symbfit{B}^{-1}\symbf{A}^{-1}\)
                  \item \(\left( \symbf{A}^{-1} \right)^\top = \left( \symbf{A}^\top \right)^{-1}\)
              \end{enumerate}
    \end{enumerate}
\end{multicols*}
\end{document}